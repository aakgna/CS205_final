{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "#In this function we are preparing the training data to be processed by the Generative Adversarial Network (GAN), it will load the image from the disk and then convert it RGB. The pixel values need to be normalized so that it is better for the training. The image is also resized to a fixed size (128x128).\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert('RGB')\n",
    "    img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "    img_array = np.array(img).astype(np.float32)\n",
    "    img_array = (img_array - 127.5) / 127.5 # Normalize to [-1,1]\n",
    "    return img_array\n",
    "data_dirs = [\n",
    "    '/kaggle/input/cubicasa5k/cubicasa5k/cubicasa5k/high_quality',\n",
    "]\n",
    "\n",
    "all_image_paths = []\n",
    "for d in data_dirs:\n",
    "    for root, dirs, files in os.walk(d):\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith('.png'):\n",
    "                full_path = os.path.join(root, filename)\n",
    "                if os.path.exists(full_path):\n",
    "                    all_image_paths.append(full_path)\n",
    "\n",
    "print(\"Total valid images found:\", len(all_image_paths))\n",
    "\n",
    "#How can we make sure that the images are correctly processed and formatted? This function takes the load_and_preprocess_image() function and the TensorFlow provided numpy_function to integrate into the data pipeline.\n",
    "def process_path(file_path):\n",
    "    img = tf.numpy_function(func=load_and_preprocess_image, inp=[file_path], Tout=tf.float32)\n",
    "    img.set_shape([IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "    return img\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "dataset = dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "BATCH_SIZE = 64\n",
    "dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "#We need to classify whether an image is real or generated, we do this via the def_discriminator() function. The function will define the discriminator model, extract features, and stabilize the training.\n",
    "def def_discriminator():\n",
    "    model = tf.keras.Sequential(name=\"discriminator\")\n",
    "    model.add(tf.keras.layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', \n",
    "                                     input_shape=[IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS],\n",
    "                                     kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same',\n",
    "                                     kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same',\n",
    "                                     kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same',\n",
    "                                     kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same',\n",
    "                                     kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "#This is our generator function. It will define the generator model which will start with a dense layer and reshape the latent vector into a small 4x4 map. The purpose of this function is to generation fake images.\n",
    "def def_generator():\n",
    "    model = tf.keras.Sequential(name=\"generator\")\n",
    "    n_nodes = 256 * 4 * 4\n",
    "    model.add(tf.keras.layers.Dense(n_nodes, input_dim=100, kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.Reshape((4, 4, 256)))\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', \n",
    "                                             activation='relu', kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', \n",
    "                                             activation='relu', kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', \n",
    "                                             activation='relu', kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', \n",
    "                                             activation='relu', kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', \n",
    "                                             activation='relu', kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.Conv2D(3, (4, 4), activation='tanh', padding='same'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "generator = def_generator()\n",
    "discriminator = def_discriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "# Loss functions\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False) \n",
    "\n",
    "#In order to distinguish between the real images and the fake images, we will be using the discriminator loss function. This will label all of the real images with a 1 and the fake images with a 0. The total loss is calculated by adding the real loss to the fake loss.\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "#To make the generator create more realistic images we are challenging the generator to trick the discriminator into thinking the fake images are real.\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    return tf.random.normal([n_samples, latent_dim])\n",
    "\n",
    "#This is the function where we are actually generating the batch of images. We save any generated images to the disk. The purpose of this generator is to visualize the progress.\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    \n",
    "    # Scale images from [-1,1] to [0,1]\n",
    "    predictions = (predictions + 1) / 2.0\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i])\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Epoch {epoch}\")\n",
    "    \n",
    "    # Save the image\n",
    "    filename = f\"generated_epoch_{epoch}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN CORE FUNCTION: This is where our GAN training actually occurs. We generate fake images, pass the real and fake images through the discriminator, calculate the generator and discriminator losses, and then compute the gradient for optimization.\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = generate_latent_points(100, BATCH_SIZE)\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "    \n",
    "    return gen_loss, disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
   "#While the train_step() is where we are actually doing the training this function manages all of the steps. We call train_step() on each batch and save the generated images to model the checkpoints. As the generator gets better at creating realistic images the discriminator is also training to improve on how it detects the fakes.\n",
    "def train(dataset, epochs):\n",
    "    seed = generate_latent_points(100, 16)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        print(f\"Starting epoch {epoch+1}/{epochs}...\")\n",
    "        \n",
    "        batch_count = 0\n",
    "        for image_batch in dataset:\n",
    "            g_loss, d_loss = train_step(image_batch)\n",
    "            batch_count += 1\n",
    "            \n",
    "            if batch_count % 10 == 0:\n",
    "                print(f\">Epoch {epoch+1}, Batch {batch_count}, D_loss={d_loss:.3f}, G_loss={g_loss:.3f}\")\n",
    "        \n",
    "        generate_and_save_images(generator, epoch+1, seed)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            generator.save(f'generator_model_epoch_{epoch+1}.h5')\n",
    "            discriminator.save(f'discriminator_model_epoch_{epoch+1}.h5')\n",
    "        \n",
    "        print(f\"Time for epoch {epoch+1} is {time.time()-start:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "print(\"Starting training...\")\n",
    "train(dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We call the generator to create a set of test images so that we can test after each training we do.\n",
    "def test_generator(generator_model, num_samples=16):\n",
    "    print(\"Generating test samples...\")\n",
    "    \n",
    "    noise = tf.random.normal([num_samples, 100])\n",
    "    generated_images = generator_model(noise, training=False)\n",
    "    generated_images = (generated_images + 1) / 2.0\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(generated_images[i])\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"test_generated_samples.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Test samples generated and saved as 'test_generated_samples.png'\")\n",
    "\n",
    "test_generator(generator)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5745102,
     "sourceId": 9498128,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
