{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9498128,"sourceType":"datasetVersion","datasetId":5745102}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom PIL import Image\nimport time\n\n# ================================\n# 1. Data Loading & Preprocessing\n# ================================\n\n# Define the image size and channels\nIMG_HEIGHT = 128\nIMG_WIDTH = 128\nIMG_CHANNELS = 3\n\ndef load_and_preprocess_image(image_path):\n    \"\"\"\n    Load an image from path, resize it to (IMG_HEIGHT, IMG_WIDTH), \n    and normalize pixel values to [-1,1].\n    \"\"\"\n    # Open the image using PIL.\n    img = Image.open(image_path)\n    \n    # Convert to RGB\n    img = img.convert('RGB')\n    \n    # Resize the image.\n    img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n    \n    # Convert image to numpy array.\n    img_array = np.array(img).astype(np.float32)\n    \n    # Normalize to [-1,1]\n    img_array = (img_array - 127.5) / 127.5\n    \n    return img_array\n\n# List directories containing PNG files\ndata_dirs = [\n    '/kaggle/input/cubicasa5k/cubicasa5k/cubicasa5k/colorful',\n    # Add more directories as needed\n]\n\n# Gather file paths, excluding .svg files.\nall_image_paths = []\nfor d in data_dirs:\n    for root, dirs, files in os.walk(d):\n        for filename in files:\n            if filename.lower().endswith('.png'):\n                full_path = os.path.join(root, filename)\n                if os.path.exists(full_path):\n                    all_image_paths.append(full_path)\n\nprint(\"Total valid images found:\", len(all_image_paths))\n\n# Create a tf.data.Dataset from the file paths.\ndef process_path(file_path):\n    img = tf.numpy_function(func=load_and_preprocess_image, inp=[file_path], Tout=tf.float32)\n    # Set the shape so TF knows the dimensions.\n    img.set_shape([IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n    return img\n\ndataset = tf.data.Dataset.from_tensor_slices(all_image_paths)\ndataset = dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\nBATCH_SIZE = 64\ndataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n# ================================\n# 2. Define the DCGAN Architecture (Based on Reference)\n# ================================\n\n# Using TensorFlow's RandomNormal initializer for weights initialization\n# This matches the initialization strategy in the reference code\ninitializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n# Discriminator model\ndef make_discriminator_model():\n    model = tf.keras.Sequential(name=\"discriminator\")\n    \n    # First convolutional layer\n    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', \n                                     input_shape=[IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS],\n                                     kernel_initializer=initializer))\n    model.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n    \n    # Second convolutional layer with batch normalization\n    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same',\n                                     kernel_initializer=initializer))\n    model.add(tf.keras.layers.BatchNormalization())\n    \n    # Third convolutional layer with batch normalization\n    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same',\n                                     kernel_initializer=initializer))\n    model.add(tf.keras.layers.BatchNormalization())\n    \n    # Fourth convolutional layer with batch normalization\n    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same',\n                                     kernel_initializer=initializer))\n    model.add(tf.keras.layers.BatchNormalization())\n    \n    # Fifth convolutional layer with batch normalization\n    model.add(tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same',\n                                     kernel_initializer=initializer))\n    model.add(tf.keras.layers.BatchNormalization())\n    \n    # Flatten and output layer\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n    \n    return model\n\n# Generator model\ndef make_generator_model():\n    model = tf.keras.Sequential(name=\"generator\")\n    \n    # Foundation for 4x4 image\n    n_nodes = 256 * 4 * 4\n    model.add(tf.keras.layers.Dense(n_nodes, input_dim=100, kernel_initializer=initializer))\n    model.add(tf.keras.layers.Reshape((4, 4, 256)))\n    \n    # Upsample to 8x8\n    model.add(tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', \n                                             activation='relu', kernel_initializer=initializer))\n    \n    # Upsample to 16x16\n    model.add(tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', \n                                             activation='relu', kernel_initializer=initializer))\n    \n    # Upsample to 32x32\n    model.add(tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', \n                                             activation='relu', kernel_initializer=initializer))\n    \n    # Upsample to 64x64\n    model.add(tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', \n                                             activation='relu', kernel_initializer=initializer))\n    \n    # Upsample to 128x128\n    model.add(tf.keras.layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', \n                                             activation='relu', kernel_initializer=initializer))\n    \n    # Output layer\n    model.add(tf.keras.layers.Conv2D(3, (3, 3), activation='tanh', padding='same'))\n    \n    return model\n\n# Create the models\ngenerator = make_generator_model()\ndiscriminator = make_discriminator_model()\n\n# ================================\n# 3. Define Losses and Optimizers\n# ================================\n\n# Using Adam optimizer with parameters from reference code\ngenerator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n\n# Loss functions\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)  # Changed to match sigmoid output\n\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss\n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)\n\n# ================================\n# 4. Helper Functions\n# ================================\n\n# Generate latent points for generator input\ndef generate_latent_points(latent_dim, n_samples):\n    return tf.random.normal([n_samples, latent_dim])\n\n# Generate and save images\ndef generate_and_save_images(model, epoch, test_input):\n    predictions = model(test_input, training=False)\n    \n    # Scale images from [-1,1] to [0,1]\n    predictions = (predictions + 1) / 2.0\n    \n    fig = plt.figure(figsize=(4, 4))\n    \n    for i in range(predictions.shape[0]):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(predictions[i])\n        plt.axis('off')\n    \n    plt.suptitle(f\"Epoch {epoch}\")\n    \n    # Save the image\n    filename = f\"generated_epoch_{epoch}.png\"\n    plt.savefig(filename)\n    plt.close()\n\n# ================================\n# 5. Training Step\n# ================================\n\n@tf.function\ndef train_step(images):\n    noise = generate_latent_points(100, BATCH_SIZE)\n    \n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training=True)\n        \n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n        \n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n    \n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n    \n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n    \n    return gen_loss, disc_loss\n\n# ================================\n# 6. Training Loop\n# ================================\n\ndef train(dataset, epochs):\n    # Seed for consistent image generation\n    seed = generate_latent_points(100, 16)\n    \n    for epoch in range(epochs):\n        start = time.time()\n        print(f\"Starting epoch {epoch+1}/{epochs}...\")\n        \n        batch_count = 0\n        for image_batch in dataset:\n            g_loss, d_loss = train_step(image_batch)\n            batch_count += 1\n            \n            # Print batch progress\n            if batch_count % 10 == 0:\n                print(f\">Epoch {epoch+1}, Batch {batch_count}, D_loss={d_loss:.3f}, G_loss={g_loss:.3f}\")\n        \n        # Generate and save images\n        generate_and_save_images(generator, epoch+1, seed)\n        \n        # Save the model periodically\n        if (epoch + 1) % 10 == 0:\n            generator.save(f'generator_model_epoch_{epoch+1}.h5')\n            discriminator.save(f'discriminator_model_epoch_{epoch+1}.h5')\n        \n        print(f\"Time for epoch {epoch+1} is {time.time()-start:.2f} sec\")\n\n# ================================\n# 7. Run Training\n# ================================\n\nEPOCHS = 100\nprint(\"Starting training...\")\ntrain(dataset, EPOCHS)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-12T19:02:08.869633Z","iopub.execute_input":"2025-03-12T19:02:08.869818Z"}},"outputs":[{"name":"stdout","text":"Total valid images found: 700\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\nStarting epoch 1/100...\n>Epoch 1, Batch 10, D_loss=0.299, G_loss=2.042\nTime for epoch 1 is 121.63 sec\nStarting epoch 2/100...\n>Epoch 2, Batch 10, D_loss=0.110, G_loss=6.859\nTime for epoch 2 is 109.05 sec\nStarting epoch 3/100...\n>Epoch 3, Batch 10, D_loss=0.128, G_loss=7.050\nTime for epoch 3 is 105.87 sec\nStarting epoch 4/100...\n>Epoch 4, Batch 10, D_loss=0.695, G_loss=1.448\nTime for epoch 4 is 106.26 sec\nStarting epoch 5/100...\n>Epoch 5, Batch 10, D_loss=0.590, G_loss=1.066\nTime for epoch 5 is 105.85 sec\nStarting epoch 6/100...\n>Epoch 6, Batch 10, D_loss=0.065, G_loss=3.573\nTime for epoch 6 is 107.60 sec\nStarting epoch 7/100...\n>Epoch 7, Batch 10, D_loss=0.167, G_loss=2.310\nTime for epoch 7 is 105.90 sec\nStarting epoch 8/100...\n>Epoch 8, Batch 10, D_loss=0.757, G_loss=0.848\nTime for epoch 8 is 142.91 sec\nStarting epoch 9/100...\n>Epoch 9, Batch 10, D_loss=0.192, G_loss=2.500\nTime for epoch 9 is 105.15 sec\nStarting epoch 10/100...\n>Epoch 10, Batch 10, D_loss=0.219, G_loss=2.554\nTime for epoch 10 is 104.58 sec\nStarting epoch 11/100...\n>Epoch 11, Batch 10, D_loss=0.133, G_loss=2.869\nTime for epoch 11 is 103.62 sec\nStarting epoch 12/100...\n>Epoch 12, Batch 10, D_loss=0.174, G_loss=2.688\nTime for epoch 12 is 102.81 sec\nStarting epoch 13/100...\n>Epoch 13, Batch 10, D_loss=0.571, G_loss=1.299\nTime for epoch 13 is 105.27 sec\nStarting epoch 14/100...\n>Epoch 14, Batch 10, D_loss=0.454, G_loss=2.720\nTime for epoch 14 is 104.35 sec\nStarting epoch 15/100...\n>Epoch 15, Batch 10, D_loss=0.151, G_loss=3.819\nTime for epoch 15 is 105.26 sec\nStarting epoch 16/100...\n>Epoch 16, Batch 10, D_loss=0.275, G_loss=4.419\nTime for epoch 16 is 102.33 sec\nStarting epoch 17/100...\n>Epoch 17, Batch 10, D_loss=0.258, G_loss=2.536\nTime for epoch 17 is 104.23 sec\nStarting epoch 18/100...\n>Epoch 18, Batch 10, D_loss=0.368, G_loss=2.259\nTime for epoch 18 is 104.53 sec\nStarting epoch 19/100...\n>Epoch 19, Batch 10, D_loss=0.277, G_loss=2.544\nTime for epoch 19 is 104.11 sec\nStarting epoch 20/100...\n>Epoch 20, Batch 10, D_loss=0.260, G_loss=3.726\nTime for epoch 20 is 103.35 sec\nStarting epoch 21/100...\n>Epoch 21, Batch 10, D_loss=0.294, G_loss=2.527\nTime for epoch 21 is 103.67 sec\nStarting epoch 22/100...\n>Epoch 22, Batch 10, D_loss=0.259, G_loss=2.860\nTime for epoch 22 is 102.42 sec\nStarting epoch 23/100...\n>Epoch 23, Batch 10, D_loss=1.411, G_loss=1.136\nTime for epoch 23 is 101.37 sec\nStarting epoch 24/100...\n>Epoch 24, Batch 10, D_loss=0.581, G_loss=1.380\nTime for epoch 24 is 103.54 sec\nStarting epoch 25/100...\n>Epoch 25, Batch 10, D_loss=0.311, G_loss=2.504\nTime for epoch 25 is 102.69 sec\nStarting epoch 26/100...\n>Epoch 26, Batch 10, D_loss=0.304, G_loss=2.651\nTime for epoch 26 is 105.05 sec\nStarting epoch 27/100...\n>Epoch 27, Batch 10, D_loss=0.222, G_loss=2.908\nTime for epoch 27 is 105.64 sec\nStarting epoch 28/100...\n>Epoch 28, Batch 10, D_loss=0.198, G_loss=2.759\nTime for epoch 28 is 103.04 sec\nStarting epoch 29/100...\n>Epoch 29, Batch 10, D_loss=0.263, G_loss=2.872\nTime for epoch 29 is 103.55 sec\nStarting epoch 30/100...\n>Epoch 30, Batch 10, D_loss=0.146, G_loss=3.576\nTime for epoch 30 is 104.03 sec\nStarting epoch 31/100...\n>Epoch 31, Batch 10, D_loss=0.163, G_loss=3.096\nTime for epoch 31 is 103.87 sec\nStarting epoch 32/100...\n>Epoch 32, Batch 10, D_loss=0.213, G_loss=2.946\nTime for epoch 32 is 102.96 sec\nStarting epoch 33/100...\n>Epoch 33, Batch 10, D_loss=0.263, G_loss=3.289\nTime for epoch 33 is 104.50 sec\nStarting epoch 34/100...\n>Epoch 34, Batch 10, D_loss=0.130, G_loss=3.936\nTime for epoch 34 is 104.74 sec\nStarting epoch 35/100...\n>Epoch 35, Batch 10, D_loss=0.170, G_loss=3.120\nTime for epoch 35 is 102.59 sec\nStarting epoch 36/100...\n>Epoch 36, Batch 10, D_loss=0.365, G_loss=4.786\nTime for epoch 36 is 101.04 sec\nStarting epoch 37/100...\n>Epoch 37, Batch 10, D_loss=0.180, G_loss=4.206\nTime for epoch 37 is 102.47 sec\nStarting epoch 38/100...\n>Epoch 38, Batch 10, D_loss=0.153, G_loss=2.672\nTime for epoch 38 is 103.19 sec\nStarting epoch 39/100...\n>Epoch 39, Batch 10, D_loss=0.273, G_loss=2.336\nTime for epoch 39 is 101.81 sec\nStarting epoch 40/100...\n>Epoch 40, Batch 10, D_loss=0.061, G_loss=4.508\nTime for epoch 40 is 104.47 sec\nStarting epoch 41/100...\n>Epoch 41, Batch 10, D_loss=0.138, G_loss=3.671\nTime for epoch 41 is 102.97 sec\nStarting epoch 42/100...\n>Epoch 42, Batch 10, D_loss=0.255, G_loss=3.985\nTime for epoch 42 is 102.75 sec\nStarting epoch 43/100...\n>Epoch 43, Batch 10, D_loss=1.235, G_loss=0.963\nTime for epoch 43 is 103.27 sec\nStarting epoch 44/100...\n>Epoch 44, Batch 10, D_loss=0.318, G_loss=2.318\nTime for epoch 44 is 102.66 sec\nStarting epoch 45/100...\n>Epoch 45, Batch 10, D_loss=0.158, G_loss=3.261\nTime for epoch 45 is 102.93 sec\nStarting epoch 46/100...\n>Epoch 46, Batch 10, D_loss=0.152, G_loss=2.948\nTime for epoch 46 is 102.54 sec\nStarting epoch 47/100...\n>Epoch 47, Batch 10, D_loss=0.130, G_loss=3.060\nTime for epoch 47 is 103.22 sec\nStarting epoch 48/100...\n>Epoch 48, Batch 10, D_loss=0.185, G_loss=2.672\nTime for epoch 48 is 102.78 sec\nStarting epoch 49/100...\n>Epoch 49, Batch 10, D_loss=0.225, G_loss=3.304\nTime for epoch 49 is 101.51 sec\nStarting epoch 50/100...\n>Epoch 50, Batch 10, D_loss=0.086, G_loss=3.962\nTime for epoch 50 is 102.54 sec\nStarting epoch 51/100...\n>Epoch 51, Batch 10, D_loss=0.132, G_loss=5.125\nTime for epoch 51 is 104.40 sec\nStarting epoch 52/100...\n>Epoch 52, Batch 10, D_loss=0.110, G_loss=3.240\nTime for epoch 52 is 103.61 sec\nStarting epoch 53/100...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def test_generator(generator_model, num_samples=16):\n    \"\"\"\n    Generate sample images using the trained generator.\n    \n    Args:\n        generator_model: The trained generator model\n        num_samples: Number of images to generate\n    \"\"\"\n    print(\"Generating test samples...\")\n    \n    # Generate random noise vectors\n    noise = tf.random.normal([num_samples, 100])\n    \n    # Generate images\n    generated_images = generator_model(noise, training=False)\n    \n    # Rescale images from [-1,1] to [0,1]\n    generated_images = (generated_images + 1) / 2.0\n    \n    # Plot the generated images\n    fig = plt.figure(figsize=(4, 4))\n    for i in range(num_samples):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(generated_images[i])\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.savefig(\"test_generated_samples.png\")\n    plt.show()\n    \n    print(\"Test samples generated and saved as 'test_generated_samples.png'\")\n\n# Example usage:\n# After training or loading a saved model:\ntest_generator(generator)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}